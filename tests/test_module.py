def test_SegDETRHead():
    from src.seg_head.seg_detr_head import SegDETRHead
    train_cfg = {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0, 'box_format': 'xywh'}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'assigner_with_mask': {'type': 'HungarianAssigner_multi_info', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0, 'box_format': 'xywh'}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}, 'mask_cost': {'type': 'DiceCost', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'sampler_with_mask': {'type': 'PseudoSampler_segformer'}}
    transformer = {'type': 'SegDeformableTransformer', 'encoder': {'type': 'DetrTransformerEncoder', 'num_layers': 6, 'transformerlayers': {'type': 'BaseTransformerLayer', 'attn_cfgs': {'type': 'MultiScaleDeformableAttention', 'embed_dims': 256, 'num_levels': 4}, 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'ffn', 'norm')}}, 'decoder': {'type': 'DeformableDetrTransformerDecoder', 'num_layers': 6, 'return_intermediate': True, 'transformerlayers': {'type': 'DetrTransformerDecoderLayer', 'attn_cfgs': [{'type': 'MultiheadAttention', 'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1}, {'type': 'MultiScaleDeformableAttention', 'embed_dims': 256, 'num_levels': 4}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}}
    kwargs = {'num_query': 300, 'num_classes': 4, 'num_things_classes': 3, 'num_stuff_classes': 1, 'in_channels': 2048, 'sync_cls_avg_factor': True, 'positional_encoding': {'type': 'SinePositionalEncoding', 'num_feats': 128, 'normalize': True, 'offset': -0.5}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}}
    head = SegDETRHead(train_cfg=train_cfg,
                transformer=transformer,
                **kwargs)
   
    
    
def test_BEVFormerEncoder():
    from src.track_head.custom_encoder import BEVFormerEncoder
    pc_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
    encoder = BEVFormerEncoder(pc_range=pc_range,num_points_in_pillar=4)


def test_occ_head():
    from src.occ_head.occ_head import OccHead
    cfg = {'type': 'OccHead', 'grid_conf': {'xbound': [-50.0, 50.0, 0.5], 'ybound': [-50.0, 50.0, 0.5], 'zbound': [-10.0, 10.0, 20.0]}, 'ignore_index': 255, 'bev_proj_dim': 256, 'bev_proj_nlayers': 4, 'attn_mask_thresh': 0.3, 'transformer_decoder': {'type': 'DetrTransformerDecoder', 'return_intermediate': True, 'num_layers': 5, 'transformerlayers': {'type': 'DetrTransformerDecoderLayer', 'attn_cfgs': {'type': 'MultiheadAttention', 'embed_dims': 256, 'num_heads': 8, 'attn_drop': 0.0, 'proj_drop': 0.0, 'dropout_layer': None, 'batch_first': False}, 'ffn_cfgs': {'type': 'FFN', 'embed_dims': 256, 'feedforward_channels': 2048, 'num_fcs': 2, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'ffn_drop': 0.0, 'dropout_layer': None, 'add_identity': True}, 'feedforward_channels': 2048, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}, 'init_cfg': None}, 'query_dim': 256, 'query_mlp_layers': 3, 'aux_loss_weight': 1.0, 'loss_mask': {'type': 'FieryBinarySegmentationLoss', 'use_top_k': True, 'top_k_ratio': 0.25, 'future_discount': 0.95, 'loss_weight': 5.0, 'ignore_index': 255}, 'loss_dice': {'type': 'DiceLossWithMasks', 'use_sigmoid': True, 'activate': True, 'reduction': 'mean', 'naive_dice': True, 'eps': 1.0, 'ignore_index': 255, 'loss_weight': 1.0}, 'pan_eval': True, 'test_seg_thresh': 0.1, 'test_with_track_score': True}
    cfg.pop('type')
    occhead_instance = OccHead(**cfg)

    
def test_motion_head():
    from src.motion_head.motion_head import MotionHead
    cfg = {'type': 'MotionHead', 'bev_h': 200, 'bev_w': 200, 'num_query': 300, 'num_classes': 10, 'predict_steps': 12, 'predict_modes': 6, 'embed_dims': 256, 'loss_traj': {'type': 'TrajLoss', 'use_variance': True, 'cls_loss_weight': 0.5, 'nll_loss_weight': 0.5, 'loss_weight_minade': 0.0, 'loss_weight_minfde': 0.25}, 'num_cls_fcs': 3, 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'group_id_list': [[0, 1, 2, 3, 4], [6, 7], [8], [5, 9]], 'num_anchor': 6, 'use_nonlinear_optimizer': True, 'anchor_info_path': 'weights/motion_anchor_infos_mode6.pkl', 'transformerlayers': {'type': 'MotionTransformerDecoder', 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'embed_dims': 256, 'num_layers': 3, 'transformerlayers': {'type': 'MotionTransformerAttentionLayer', 'batch_first': True, 'attn_cfgs': [{'type': 'MotionDeformableAttention', 'num_steps': 12, 'embed_dims': 256, 'num_levels': 1, 'num_heads': 8, 'num_points': 4, 'sample_index': -1}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('cross_attn', 'norm', 'ffn', 'norm')}}}
    motionhead_instance = MotionHead(**cfg)

    
def test_bevformer_decoder():
    from src.track_head.CustomMSDeformableAttention import DetectionTransformerDecoder, CustomMSDeformableAttention
    from src.utils.builder import build_transformer_layer_sequence
    cfg = {'type': 'DetectionTransformerDecoder', 'num_layers': 6, 'return_intermediate': True, 'transformerlayers': {'type': 'DetrTransformerDecoderLayer', 'attn_cfgs': [{'type': 'MultiheadAttention', 'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1}, {'type': 'CustomMSDeformableAttention', 'embed_dims': 256, 'num_levels': 1}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}
    decoder = build_transformer_layer_sequence(cfg)
    

def test_PerceptionTransformer():
    cfg = {'type': 'PerceptionTransformer', 'rotate_prev_bev': True, 'use_shift': True, 'use_can_bus': True, 'embed_dims': 256, 'encoder': {'type': 'BEVFormerEncoder', 'num_layers': 6, 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'num_points_in_pillar': 4, 'return_intermediate': False, 'transformerlayers': {'type': 'BEVFormerLayer', 'attn_cfgs': [{'type': 'TemporalSelfAttention', 'embed_dims': 256, 'num_levels': 1}, {'type': 'SpatialCrossAttention', 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'deformable_attention': {'type': 'MSDeformableAttention3D', 'embed_dims': 256, 'num_points': 8, 'num_levels': 4}, 'embed_dims': 256}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}, 'decoder': {'type': 'DetectionTransformerDecoder', 'num_layers': 6, 'return_intermediate': True, 'transformerlayers': {'type': 'DetrTransformerDecoderLayer', 'attn_cfgs': [{'type': 'MultiheadAttention', 'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1}, {'type': 'CustomMSDeformableAttention', 'embed_dims': 256, 'num_levels': 1}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}}
    from src.track_head.transformer import PerceptionTransformer
    transformer = PerceptionTransformer(**cfg)
    

    
    
def test_MVXTwoStageDetector():
    from src.modules.mvx_two_stage import MVXTwoStageDetector
    img_backbone = {'type': 'ResNet', 'depth': 101, 'num_stages': 4, 'out_indices': (1, 2, 3), 'frozen_stages': 4, 'norm_cfg': {'type': 'BN2d', 'requires_grad': False}, 'norm_eval': True, 'style': 'caffe', 'dcn': {'type': 'DCNv2', 'deform_groups': 1, 'fallback_on_stride': False}, 'stage_with_dcn': (False, False, True, True)}
    img_neck = {'type': 'FPN', 'in_channels': [512, 1024, 2048], 'out_channels': 256, 'start_level': 0, 'add_extra_convs': 'on_output', 'num_outs': 4, 'relu_before_extra_convs': True}
    pts_bbox_head = {'type': 'BEVFormerTrackHead', 'bev_h': 200, 'bev_w': 200, 'num_query': 900, 'num_classes': 10, 'in_channels': 256, 'sync_cls_avg_factor': True, 'with_box_refine': True, 'as_two_stage': False, 'past_steps': 4, 'fut_steps': 4, 'transformer': {'type': 'PerceptionTransformer', 'rotate_prev_bev': True, 'use_shift': True, 'use_can_bus': True, 'embed_dims': 256, 'encoder': {'type': 'BEVFormerEncoder', 'num_layers': 6, 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'num_points_in_pillar': 4, 'return_intermediate': False, 'transformerlayers': {'type': 'BEVFormerLayer', 'attn_cfgs': [{'type': 'TemporalSelfAttention', 'embed_dims': 256, 'num_levels': 1}, {'type': 'SpatialCrossAttention', 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'deformable_attention': {'type': 'MSDeformableAttention3D', 'embed_dims': 256, 'num_points': 8, 'num_levels': 4}, 'embed_dims': 256}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}, 'decoder': {'type': 'DetectionTransformerDecoder', 'num_layers': 6, 'return_intermediate': True, 'transformerlayers': {'type': 'DetrTransformerDecoderLayer', 'attn_cfgs': [{'type': 'MultiheadAttention', 'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1}, {'type': 'CustomMSDeformableAttention', 'embed_dims': 256, 'num_levels': 1}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}}, 'bbox_coder': {'type': 'NMSFreeCoder', 'post_center_range': [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0], 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'max_num': 300, 'voxel_size': [0.2, 0.2, 8], 'num_classes': 10}, 'positional_encoding': {'type': 'LearnedPositionalEncoding', 'num_feats': 128, 'row_num_embed': 200, 'col_num_embed': 200}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 0.25}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 0.0}}
    train_cfg = None
    test_cfg = None
    pretrained = None
    detector = MVXTwoStageDetector(
            img_backbone=img_backbone,
            img_neck=img_neck,
            pts_bbox_head=pts_bbox_head,
            train_cfg=train_cfg,
            test_cfg=test_cfg,
            pretrained=pretrained,
        )
    

def test_UniADTrack():
    cfg = {'gt_iou_threshold': 0.3, 'queue_length': 3, 'use_grid_mask': True, 'video_test_mode': True, 'num_query': 900, 'num_classes': 10, 'vehicle_id_list': [0, 1, 2, 3, 4, 6, 7], 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'img_backbone': {'type': 'ResNet', 'depth': 101, 'num_stages': 4, 'out_indices': (1, 2, 3), 'frozen_stages': 4, 'norm_cfg': {'type': 'BN2d', 'requires_grad': False}, 'norm_eval': True, 'style': 'caffe', 'dcn': {'type': 'DCNv2', 'deform_groups': 1, 'fallback_on_stride': False}, 'stage_with_dcn': (False, False, True, True)}, 'img_neck': {'type': 'FPN', 'in_channels': [512, 1024, 2048], 'out_channels': 256, 'start_level': 0, 'add_extra_convs': 'on_output', 'num_outs': 4, 'relu_before_extra_convs': True}, 'freeze_img_backbone': True, 'freeze_img_neck': True, 'freeze_bn': True, 'freeze_bev_encoder': True, 'score_thresh': 0.4, 'filter_score_thresh': 0.35, 'qim_args': {'qim_type': 'QIMBase', 'merger_dropout': 0, 'update_query_pos': True, 'fp_ratio': 0.3, 'random_drop': 0.1}, 'mem_args': {'memory_bank_type': 'MemoryBank', 'memory_bank_score_thresh': 0.0, 'memory_bank_len': 4}, 'loss_cfg': {'type': 'ClipMatcher', 'num_classes': 10, 'weight_dict': None, 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2], 'assigner': {'type': 'HungarianAssigner3DTrack', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBox3DL1Cost', 'weight': 0.25}, 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 0.25}}, 'pts_bbox_head': {'type': 'BEVFormerTrackHead', 'bev_h': 200, 'bev_w': 200, 'num_query': 900, 'num_classes': 10, 'in_channels': 256, 'sync_cls_avg_factor': True, 'with_box_refine': True, 'as_two_stage': False, 'past_steps': 4, 'fut_steps': 4, 'transformer': {'type': 'PerceptionTransformer', 'rotate_prev_bev': True, 'use_shift': True, 'use_can_bus': True, 'embed_dims': 256, 'encoder': {'type': 'BEVFormerEncoder', 'num_layers': 6, 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'num_points_in_pillar': 4, 'return_intermediate': False, 'transformerlayers': {'type': 'BEVFormerLayer', 'attn_cfgs': [{'type': 'TemporalSelfAttention', 'embed_dims': 256, 'num_levels': 1}, {'type': 'SpatialCrossAttention', 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'deformable_attention': {'type': 'MSDeformableAttention3D', 'embed_dims': 256, 'num_points': 8, 'num_levels': 4}, 'embed_dims': 256}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}, 'decoder': {'type': 'DetectionTransformerDecoder', 'num_layers': 6, 'return_intermediate': True, 'transformerlayers': {'type': 'DetrTransformerDecoderLayer', 'attn_cfgs': [{'type': 'MultiheadAttention', 'embed_dims': 256, 'num_heads': 8, 'dropout': 0.1}, {'type': 'CustomMSDeformableAttention', 'embed_dims': 256, 'num_levels': 1}], 'feedforward_channels': 512, 'ffn_dropout': 0.1, 'operation_order': ('self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm')}}}, 'bbox_coder': {'type': 'NMSFreeCoder', 'post_center_range': [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0], 'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], 'max_num': 300, 'voxel_size': [0.2, 0.2, 8], 'num_classes': 10}, 'positional_encoding': {'type': 'LearnedPositionalEncoding', 'num_feats': 128, 'row_num_embed': 200, 'col_num_embed': 200}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 0.25}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 0.0}}, 'train_cfg': None, 'pretrained': None, 'test_cfg': None}
    from src.uniad_track import UniADTrack
    track  = UniADTrack(**cfg)
    

def test_UniAD():
    from src.uniad_e2e import UniAD
    cfg = \
    {'filter_score_thresh': 0.35,
    'freeze_bev_encoder': True,
    'freeze_bn': True,
    'freeze_img_backbone': True,
    'freeze_img_neck': True,
    'gt_iou_threshold': 0.3,
    'img_backbone': {'dcn': {'deform_groups': 1,
                            'fallback_on_stride': False,
                            'type': 'DCNv2'},
                    'depth': 101,
                    'frozen_stages': 4,
                    'norm_cfg': {'requires_grad': False, 'type': 'BN2d'},
                    'norm_eval': True,
                    'num_stages': 4,
                    'out_indices': (1, 2, 3),
                    'stage_with_dcn': (False, False, True, True),
                    'style': 'caffe',
                    'type': 'ResNet'},
    'img_neck': {'add_extra_convs': 'on_output',
                'in_channels': [512, 1024, 2048],
                'num_outs': 4,
                'out_channels': 256,
                'relu_before_extra_convs': True,
                'start_level': 0,
                'type': 'FPN'},
    'loss_cfg': {'assigner': {'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0},
                            'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                            'reg_cost': {'type': 'BBox3DL1Cost', 'weight': 0.25},
                            'type': 'HungarianAssigner3DTrack'},
                'code_weights': [1.0,
                                1.0,
                                1.0,
                                1.0,
                                1.0,
                                1.0,
                                1.0,
                                1.0,
                                0.2,
                                0.2],
                'loss_bbox': {'loss_weight': 0.25, 'type': 'L1Loss'},
                'loss_cls': {'alpha': 0.25,
                            'gamma': 2.0,
                            'loss_weight': 2.0,
                            'type': 'FocalLoss',
                            'use_sigmoid': True},
                'num_classes': 10,
                'type': 'ClipMatcher',
                'weight_dict': None},
    'mem_args': {'memory_bank_len': 4,
                'memory_bank_score_thresh': 0.0,
                'memory_bank_type': 'MemoryBank'},
    'motion_head': {'anchor_info_path': 'data/others/motion_anchor_infos_mode6.pkl',
                    'bev_h': 200,
                    'bev_w': 200,
                    'embed_dims': 256,
                    'group_id_list': [[0, 1, 2, 3, 4], [6, 7], [8], [5, 9]],
                    'loss_traj': {'cls_loss_weight': 0.5,
                                'loss_weight_minade': 0.0,
                                'loss_weight_minfde': 0.25,
                                'nll_loss_weight': 0.5,
                                'type': 'TrajLoss',
                                'use_variance': True},
                    'num_anchor': 6,
                    'num_classes': 10,
                    'num_cls_fcs': 3,
                    'num_query': 300,
                    'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                    'predict_modes': 6,
                    'predict_steps': 12,
                    'transformerlayers': {'embed_dims': 256,
                                        'num_layers': 3,
                                        'pc_range': [-51.2,
                                                        -51.2,
                                                        -5.0,
                                                        51.2,
                                                        51.2,
                                                        3.0],
                                        'transformerlayers': {'attn_cfgs': [{'embed_dims': 256,
                                                                                'num_heads': 8,
                                                                                'num_levels': 1,
                                                                                'num_points': 4,
                                                                                'num_steps': 12,
                                                                                'sample_index': -1,
                                                                                'type': 'MotionDeformableAttention'}],
                                                                'batch_first': True,
                                                                'feedforward_channels': 512,
                                                                'ffn_dropout': 0.1,
                                                                'operation_order': ('cross_attn',
                                                                                    'norm',
                                                                                    'ffn',
                                                                                    'norm'),
                                                                'type': 'MotionTransformerAttentionLayer'},
                                        'type': 'MotionTransformerDecoder'},
                    'type': 'MotionHead',
                    'use_nonlinear_optimizer': True},
    'num_classes': 10,
    'num_query': 900,
    'occ_head': {'attn_mask_thresh': 0.3,
                'aux_loss_weight': 1.0,
                'bev_proj_dim': 256,
                'bev_proj_nlayers': 4,
                'grid_conf': {'xbound': [-50.0, 50.0, 0.5],
                                'ybound': [-50.0, 50.0, 0.5],
                                'zbound': [-10.0, 10.0, 20.0]},
                'ignore_index': 255,
                'loss_dice': {'activate': True,
                                'eps': 1.0,
                                'ignore_index': 255,
                                'loss_weight': 1.0,
                                'naive_dice': True,
                                'reduction': 'mean',
                                'type': 'DiceLossWithMasks',
                                'use_sigmoid': True},
                'loss_mask': {'future_discount': 0.95,
                                'ignore_index': 255,
                                'loss_weight': 5.0,
                                'top_k_ratio': 0.25,
                                'type': 'FieryBinarySegmentationLoss',
                                'use_top_k': True},
                'pan_eval': True,
                'query_dim': 256,
                'query_mlp_layers': 3,
                'test_seg_thresh': 0.1,
                'test_with_track_score': True,
                'transformer_decoder': {'init_cfg': None,
                                        'num_layers': 5,
                                        'return_intermediate': True,
                                        'transformerlayers': {'attn_cfgs': {'attn_drop': 0.0,
                                                                            'batch_first': False,
                                                                            'dropout_layer': None,
                                                                            'embed_dims': 256,
                                                                            'num_heads': 8,
                                                                            'proj_drop': 0.0,
                                                                            'type': 'MultiheadAttention'},
                                                                'feedforward_channels': 2048,
                                                                'ffn_cfgs': {'act_cfg': {'inplace': True,
                                                                                        'type': 'ReLU'},
                                                                            'add_identity': True,
                                                                            'dropout_layer': None,
                                                                            'embed_dims': 256,
                                                                            'feedforward_channels': 2048,
                                                                            'ffn_drop': 0.0,
                                                                            'num_fcs': 2},
                                                                'operation_order': ('self_attn',
                                                                                    'norm',
                                                                                    'cross_attn',
                                                                                    'norm',
                                                                                    'ffn',
                                                                                    'norm'),
                                                                'type': 'DetrTransformerDecoderLayer'},
                                        'type': 'DetrTransformerDecoder'},
                'type': 'OccHead'},
    'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
    'planning_head': {'embed_dims': 256,
                    'loss_collision': [{'delta': 0.0,
                                        'type': 'CollisionLoss',
                                        'weight': 2.5},
                                        {'delta': 0.5,
                                        'type': 'CollisionLoss',
                                        'weight': 1.0},
                                        {'delta': 1.0,
                                        'type': 'CollisionLoss',
                                        'weight': 0.25}],
                    'loss_planning': {'type': 'PlanningLoss'},
                    'planning_eval': True,
                    'planning_steps': 6,
                    'type': 'PlanningHeadSingleMode',
                    'use_col_optim': True,
                    'with_adapter': True},
    'pretrained': None,
    'pts_bbox_head': {'as_two_stage': False,
                    'bbox_coder': {'max_num': 300,
                                    'num_classes': 10,
                                    'pc_range': [-51.2,
                                                -51.2,
                                                -5.0,
                                                51.2,
                                                51.2,
                                                3.0],
                                    'post_center_range': [-61.2,
                                                            -61.2,
                                                            -10.0,
                                                            61.2,
                                                            61.2,
                                                            10.0],
                                    'type': 'NMSFreeCoder',
                                    'voxel_size': [0.2, 0.2, 8]},
                    'bev_h': 200,
                    'bev_w': 200,
                    'fut_steps': 4,
                    'in_channels': 256,
                    'loss_bbox': {'loss_weight': 0.25, 'type': 'L1Loss'},
                    'loss_cls': {'alpha': 0.25,
                                    'gamma': 2.0,
                                    'loss_weight': 2.0,
                                    'type': 'FocalLoss',
                                    'use_sigmoid': True},
                    'loss_iou': {'loss_weight': 0.0, 'type': 'GIoULoss'},
                    'num_classes': 10,
                    'num_query': 900,
                    'past_steps': 4,
                    'positional_encoding': {'col_num_embed': 200,
                                            'num_feats': 128,
                                            'row_num_embed': 200,
                                            'type': 'LearnedPositionalEncoding'},
                    'sync_cls_avg_factor': True,
                    'transformer': {'decoder': {'num_layers': 6,
                                                'return_intermediate': True,
                                                'transformerlayers': {'attn_cfgs': [{'dropout': 0.1,
                                                                                        'embed_dims': 256,
                                                                                        'num_heads': 8,
                                                                                        'type': 'MultiheadAttention'},
                                                                                    {'embed_dims': 256,
                                                                                        'num_levels': 1,
                                                                                        'type': 'CustomMSDeformableAttention'}],
                                                                        'feedforward_channels': 512,
                                                                        'ffn_dropout': 0.1,
                                                                        'operation_order': ('self_attn',
                                                                                            'norm',
                                                                                            'cross_attn',
                                                                                            'norm',
                                                                                            'ffn',
                                                                                            'norm'),
                                                                        'type': 'DetrTransformerDecoderLayer'}
    ,
                                                'type': 'DetectionTransformerDecoder'},
                                    'embed_dims': 256,
                                    'encoder': {'num_layers': 6,
                                                'num_points_in_pillar': 4,
                                                'pc_range': [-51.2,
                                                                -51.2,
                                                                -5.0,
                                                                51.2,
                                                                51.2,
                                                                3.0],
                                                'return_intermediate': False,
                                                'transformerlayers': {'attn_cfgs': [{'embed_dims': 256,
                                                                                        'num_levels': 1,
                                                                                        'type': 'TemporalSelfAttention'},
                                                                                    {'deformable_attention': {'embed_dims': 256,
                                                                                                                'num_levels': 4,
                                                                                                                'num_points': 8,
                                                                                                                'type': 'MSDeformableAttention3D'},
                                                                                        'embed_dims': 256,
                                                                                        'pc_range': [-51.2,
                                                                                                    -51.2,
                                                                                                    -5.0,
                                                                                                    51.2,
                                                                                                    51.2,
                                                                                                    3.0],
                                                                                        'type': 'SpatialCrossAttention'}],
                                                                        'feedforward_channels': 512,
                                                                        'ffn_dropout': 0.1,
                                                                        'operation_order': ('self_attn',
                                                                                            'norm',
                                                                                            'cross_attn',
                                                                                            'norm',
                                                                                            'ffn',
                                                                                            'norm'),
                                                                        'type': 'BEVFormerLayer'},
                                                'type': 'BEVFormerEncoder'},
                                    'rotate_prev_bev': True,
                                    'type': 'PerceptionTransformer',
                                    'use_can_bus': True,
                                    'use_shift': True},
                    'type': 'BEVFormerTrackHead',
                    'with_box_refine': True},
    'qim_args': {'fp_ratio': 0.3,
                'merger_dropout': 0,
                'qim_type': 'QIMBase',
                'random_drop': 0.1,
                'update_query_pos': True},
    'queue_length': 3,
    'score_thresh': 0.4,
    'seg_head': {'as_two_stage': False,
                'bev_h': 200,
                'bev_w': 200,
                'canvas_size': (200, 200),
                'in_channels': 2048,
                'loss_bbox': {'loss_weight': 5.0, 'type': 'L1Loss'},
                'loss_cls': {'alpha': 0.25,
                            'gamma': 2.0,
                            'loss_weight': 2.0,
                            'type': 'FocalLoss',
                            'use_sigmoid': True},
                'loss_iou': {'loss_weight': 2.0, 'type': 'GIoULoss'},
                'loss_mask': {'loss_weight': 2.0, 'type': 'DiceLoss'},
                'num_classes': 4,
                'num_query': 300,
                'num_stuff_classes': 1,
                'num_things_classes': 3,
                'pc_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                'positional_encoding': {'normalize': True,
                                        'num_feats': 128,
                                        'offset': -0.5,
                                        'type': 'SinePositionalEncoding'},
                'stuff_transformer_head': {'d_model': 256,
                                            'nhead': 8,
                                            'num_decoder_layers': 6,
                                            'self_attn': True,
                                            'type': 'SegMaskHead'},
                'sync_cls_avg_factor': True,
                'thing_transformer_head': {'d_model': 256,
                                            'nhead': 8,
                                            'num_decoder_layers': 4,
                                            'type': 'SegMaskHead'},
                'train_cfg': {'assigner': {'cls_cost': {'type': 'FocalLossCost',
                                                        'weight': 2.0},
                                            'iou_cost': {'iou_mode': 'giou',
                                                        'type': 'IoUCost',
                                                        'weight': 2.0},
                                            'reg_cost': {'box_format': 'xywh',
                                                        'type': 'BBoxL1Cost',
                                                        'weight': 5.0},
                                            'type': 'HungarianAssigner'},
                                'assigner_with_mask': {'cls_cost': {'type': 'FocalLossCost',
                                                                    'weight': 2.0},
                                                    'iou_cost': {'iou_mode': 'giou',
                                                                    'type': 'IoUCost',
                                                                    'weight': 2.0},
                                                    'mask_cost': {'type': 'DiceCost',
                                                                    'weight': 2.0},
                                                    'reg_cost': {'box_format': 'xywh',
                                                                    'type': 'BBoxL1Cost',
                                                                    'weight': 5.0},
                                                    'type': 'HungarianAssigner_multi_info'},
                                'sampler': {'type': 'PseudoSampler'},
                                'sampler_with_mask': {'type': 'PseudoSampler_segformer'}},
                'transformer': {'decoder': {'num_layers': 6,
                                            'return_intermediate': True,
                                            'transformerlayers': {'attn_cfgs': [{'dropout': 0.1,
                                                                                'embed_dims': 256,
                                                                                'num_heads': 8,
                                                                                'type': 'MultiheadAttention'},
                                                                                {'embed_dims': 256,
                                                                                'num_levels': 4,
                                                                                'type': 'MultiScaleDeformableAttention'}],
                                                                    'feedforward_channels': 512,
                                                                    'ffn_dropout': 0.1,
                                                                    'operation_order': ('self_attn',
                                                                                        'norm',
                                                                                        'cross_attn',
                                                                                        'norm',
                                                                                        'ffn',
                                                                                        'norm'),
                                                                    'type': 'DetrTransformerDecoderLayer'},
                                            'type': 'DeformableDetrTransformerDecoder'},
                                'encoder': {'num_layers': 6,
                                            'transformerlayers': {'attn_cfgs': {'embed_dims': 256,
                                                                                'num_levels': 4,
                                                                                'type': 'MultiScaleDeformableAttention'},
                                                                    'feedforward_channels': 512,
                                                                    'ffn_dropout': 0.1,
                                                                    'operation_order': ('self_attn',
                                                                                        'norm',
                                                                                        'ffn',
                                                                                        'norm'),
                                                                    'type': 'BaseTransformerLayer'},
                                            'type': 'DetrTransformerEncoder'},
                                'type': 'SegDeformableTransformer'},
                'type': 'PansegformerHead',
                'with_box_refine': True},
    'train_cfg': None,
    'type': 'UniAD',
    'use_grid_mask': True,
    'vehicle_id_list': [0, 1, 2, 3, 4, 6, 7],
    'video_test_mode': True}
    cfg.pop('type')
    import pdb
    pdb.set_trace()
    model = UniAD(**cfg)
    
    

    
